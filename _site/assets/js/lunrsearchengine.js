
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 2,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                           Github pages와 Jekyll 설치하기 - Windows ver.                               :               jekyll은 github pages를 지원하는 정적 웹사이트 생성기입니다. 저장되어 있는 html, markdown 파일을 그대로 가져와서 선택한 레이아웃에 따라 html 코드로 변환해 정적 웹사이트를 생성해줍니다. jekyll은 매우. . . :                                                                                                                                                                         Chloe Jungah Kim                                    26 Jun 2024                                                                                                                                                  All Stories:                                                                                                     Github pages와 Jekyll 설치하기 - Windows ver.               :       jekyll은 github pages를 지원하는 정적 웹사이트 생성기입니다. 저장되어 있는 html, markdown 파일을 그대로 가져와서 선택한 레이아웃에 따라 html 코드로 변환해 정적 웹사이트를 생성해줍니다. jekyll은 매우 가벼우며, liquid 언어를 지원하여 동적. . . :                                                                               Chloe Jungah Kim                26 Jun 2024                                                                                                                    [CUDA 7] GPU 실행시간 측정 - cudaEvent              :       GPU에서 실행 시간을 측정할 수 있는 방법은 StopWatchInterface를 사용하는 등 여러 가지가 있지만, NVIDIA에서 공식적으로 제공하는 Programming Guide에서 확인할 수 있는 내용인 cudaEvent를 소개하고자 합니다. :                                                                               Chloe Jungah Kim                15 Jan 2016                                                                                                                    [CUDA 5. 5] cpp에서 CUDA 함수 사용하기              :       이번 포스팅에서는 cpp에서 CUDA 함수를 사용하는 방법에 대하여 이야기해보겠습니다. :                                                                               Chloe Jungah Kim                07 Apr 2015                                                                                                                    [CUDA 5. 5] CUDA 메모리 성능 최적화              :       ※ 이 글은 2014년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                04 Apr 2015                                                                                                                    [CUDA 5. 0] CUDA C 확장 키워드 (CUDA C Extension) - 변수의 수식어              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                03 Apr 2015                                                                                                                    [CUDA 5. 0] CUDA C 확장 키워드 (CUDA C Extension) - 함수의 수식어              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                03 Apr 2015                               &laquo; Prev       1        2      Next &raquo; "
    }, {
    "id": 3,
    "url": "http://localhost:4000/page2/",
    "title": "Home",
    "body": "{% if page. url == “/” %}       Featured:       {% for post in site. posts %}    {% if post. featured == true %}      {% include featuredbox. html %}    {% endif %}  {% endfor %}  {% endif %}       All Stories:         {% for post in paginator. posts %}    {% include postbox. html %}    {% endfor %}    {% include pagination. html %}"
    }, {
    "id": 4,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 5,
    "url": "http://localhost:4000/jekyll-setup-windows/",
    "title": "Github pages와 Jekyll 설치하기 - Windows ver.",
    "body": "2024/06/26 - jekyll은 github pages를 지원하는 정적 웹사이트 생성기입니다. 저장되어 있는 html, markdown 파일을 그대로 가져와서 선택한 레이아웃에 따라 html 코드로 변환해 정적 웹사이트를 생성해줍니다. jekyll은 매우 가벼우며, liquid 언어를 지원하여 동적 컨텐츠 로드가 가능하다는 장점이 있습니다. 또한 markdown 언어를 사용하기 때문에 문법이 쉽고, 작성이 간편하다는 것도 장점입니다. 사실 windows는 jekyll이 공식적으로 지원되는 플랫폼은 아닙니다. 하지만 실행이 불가능한 것은 아니기 때문에 약간의 수정을 통해 실행시킬 수 있습니다. Github Pages 생성하기github 계정이 있다는 전제하에, 새 repository를 생성하는 것으로 시작합니다. github pages를 사용하기 위해서는 특정한 repository의 이름을 설정해야 하는데, githubId. github. io와 같은 형식으로 설정해줘야 합니다. github id가 아닌 다른 repository 이름을 설정하는 경우, 추가적인 세팅이 필요해지기 때문에 되도록이면 id를 사용합니다.  저의 경우에는 이미 chloeeekim. github. io repository가 있다고 표시됩니다. repository의 세팅은 변경할 내용 없이 생성해도 괜찮습니다. repository가 만들어지면 github pages도 생성이 완료된 것입니다. github pages가 잘 동작하는지 알고 싶다면, repository에 index. html이라는 이름으로 원하는 내용을 입력하고 commit 해줍니다. 약간의 시간이 지나고 나서 githubId. github. io에 접속하면, 입력한 내용이 표시되는 것을 확인할 수 있습니다. 이제 github pages를 사용할 준비는 끝났습니다. Ruby 및 Jekyll 설치하기jekyll을 사용하기 위해서는 먼저 ruby를 설치해야 합니다. ruby를 설치하는 방법은 다양하지만, windows에서는 ruby installer를 이용하면 간단하게 설치할 수 있습니다. ruby installer download 페이지에 가서 ruby installer를 다운받아 주면 됩니다.  사이트 좌측 상단을 보면 WITH DEVKIT 항목이 있는데, 꼭 Ruby+Devkit 버전을 다운받아야 합니다. 설치는 간단하게 진행되며, optional한 부분은 건드릴 필요 없이 기본 옵션으로 설치하면 됩니다. ruby installer는 windows를 기반으로 ruby 언어와 실행 환경 등을 포함하고 있습니다. 참고로 ruby installer 2. 4 버전 이전의 경우에는 devkit을 따로 설치해야 합니다. ruby installer 설치가 완료되었다면, ruby command prompt를 실행해줍니다.  12% ruby --versionruby 3. 1. 2p20 (2022-04-12 revision 4491bb740a) [x64-mingw-ucrt]ruby --version 명령어로 루비 정보가 표시된다면 정상적으로 설치가 완료된 것입니다. 그런 다음, jekyll과 bundler를 설치해 줍니다. 1gem install jekyll bundler설치가 완료되면, 다음 명령어로 jekyll이 잘 설치되었는지도 확인할 수 있습니다. 12% jekyll -vjekyll 4. 3. 3Jekyll Theme 적용기존에 존재하는 테마를 사용하지 않을 수도 있지만, jekyll의 또 다른 장점 중 하나가 무료로 제공되는 다양한 테마가 굉장히 많다는 것입니다. 다음 사이트들에서 어마어마한 테마들을 구경하고 선택할 수 있습니다.  https://jekyllthemes. org https://jekyllthemes. io/free http://themes. jekyllrc. org위 사이트에서 마음에 드는 테마를 찾아 사용하거나 혹은 github에서 jekyll-theme 등으로 검색하여 찾을 수도 있습니다. 우선 테마를 사용하여 설정을 마친 다음에는 원하는 대로 커스터마이징을 할 수 있기도 하고, 언제든 테마를 바꿀 수도 있으니 마음 편하게 테마를 고르시면 됩니다. 저는 mediumish라는 테마를 선택하였습니다. 꼭 같은 테마가 아니어도 상관 없으니, 원하시는 테마를 선택합니다. 테마를 골랐다면, 해당 테마의 github 페이지로 이동하여 code를 다운받아 줍니다. clone을 해도 상관없고, . zip 파일로 받아도 됩니다. 다운받은 파일들을 위에서 생성한 github pages repository에 옮겨줍니다. ruby command prompt에서 내 repository가 가져와진 경로로 이동하여 아래 명령어들을 순서대로 실행해줍니다. 12bundle installbundle update문제 없이 설치가 끝났다면, 로컬 서버를 실행할 시간입니다. 로컬 서버 실행아래 명령어 중 하나로 jekyll server를 로컬에서 실행할 수 있습니다. 12bundler exec jekyll servejekyll serve실행시키면 Server address: http://127. 0. 0. 1:4000/와 같이 로컬 서버 주소가 표시됩니다. 참고로 --serve 옵션을 통해 변경사항을 자동으로 감지하도록 할 수도 있습니다. 이후에는 로컬 서버에 접속하여 실제로 실행시켜 볼 수 있습니다. 각종 에러에 대처하기jekyll을 설치하고 실행할 수 있다고는 하지만, windows는 공식적으로 지원되는 플랫폼이 아니기 때문에 에러가 발생하는 경우가 있습니다. 아래에서 몇 가지 에러에 대처하는 방법을 설명하겠습니다. Liquid Exception: Incompatible character encoding: UTF-8 인코딩을 사용하는 경우 발생할 수 있는 에러입니다. 예를 들어, windows 게정명이 한글인 경우가 있을 수 있습니다. C:\User\계정명처럼 한글이 포함된 경로 때문에 에러가 발생할 수 있습니다. 이 경우 다음 명령어를 통해 UTF-8 인코딩 옵션을 켜주면 해결이 가능합니다. 1chcp 65001cannot load such file -- webrick (LoadError): webrick을 찾을 수 없어서 발생하는 에러입니다. 따라서 webrick을 추가해주면 해결이 가능합니다. 1bundle add webrickAn error occurred while installing wdm (0. 1. 1), and Bundler cannot continue. : wdm 설치에 실패하여 발생하는 에러입니다. windows에서 --watch 옵션을 사용하기 위해서는 wdm을 설치해야 하는데, 만약 --watch 옵션을 사용하지 않을 것이라면 Gemfile에서 아래 코드를 주석 처리하여 줍니다. 1gem  wdm ,  ~&gt; 0. 1. 1 , :platforms =&gt; [:mingw, :x64_mingw, :mswin]--watch 옵션을 사용하고 싶은 경우에는 현재 ruby의 버전을 특정 버전으로 낮추는 방법 밖에는 없습니다. 우선 설치되어 있는 ruby를 완전히 삭제하고, C:\ 드라이브에 있는 Ruby 관련 폴더도 삭제해줍니다. 이후 ruby 3. 1. 2-1 버전을 다운받아 설치한 후, bundle install부터 다시 실행시켜 주면 해결이 가능합니다. "
    }, {
    "id": 6,
    "url": "http://localhost:4000/python-string-formatting/",
    "title": "Python String Formatting 방법",
    "body": "2021/06/06 - python은 다양한 문자열 포맷팅 방법을 지원합니다. python의 버전에 따라 지원되는 포맷팅 방법이 달라지기도 하니 사용하는 python의 버전을 확인하고 사용하시기 바랍니다. % operatorC 스타일로 문자열을 포맷팅하는 방법입니다. python3 이전에 사용되던 방법으로, python 버전에 상관이 없으며, C 문법에 익숙하다면 간단하게 사용할 수 있습니다. % operator를 사용하는 경우, 포맷팅하고자 하는 자료형의 데이터 타입이 동일해야 하는데, 때문에 자료형 별로 어떠한 문자열 포맷 코드를 사용해야 하는지를 알고 있어야 합니다. 사용 예시는 다음과 같습니다. 12&gt;&gt;&gt;  Hello %s  %  World 'Hello World'많이 사용되는 포맷 코드는 다음과 같습니다. 참고로 % 문자 자체를 출력하고 싶은 경우에는 %%를 사용합니다.       포맷 코드   설명         %s   문자열       %d   정수       %f   실수       %o   8진수       %x, %X   16진수 (lowercase, uppercase)       %c   단일 문자   포맷 코드와 연결된 데이터의 타입이 다를 경우에는 에러가 발생하게 됩니다. 예를 들어, %d 포맷 코드를 사용하였는데 문자열을 넣어주는 경우 TypeError가 발생합니다. 하지만 특이하게 %s 포맷 코드의 경우에는 어떠한 타입의 값이건 넣을 수 있습니다. 1234&gt;&gt;&gt;  I am %s years old  % 31'I am 31 years old'&gt;&gt;&gt;  Pi number is %s  % 3. 14'Pi number is 3. 14'위와 같이 정수 타입인 %d나 실수 타입인 %f를 쓰지 않아도 %s를 사용하면 자동으로 넘어오는 값들을 문자열로 바꾸어 대입해주게 됩니다. 여러 개의 값 사용하기: 문자열 안에 여러 개의 포맷 코드를 사용하는 경우에는 % 뒤에 오는 값들을 콤마로 구분하여 소괄호로 감싸야 합니다. 소괄호로 묶지 않으면 에러가 발생하게 됩니다. 값들은 순서대로 연결되며, 포맷 코드의 개수와 변수의 개수가 동일하여야 합니다. 1234&gt;&gt;&gt;  %d + %d = %d  % (1, 2, 3)'1 + 2 = 3'&gt;&gt;&gt;  Today is %d %s  % (6, 'June')'Today is 6 June'값들이 소괄호로 묶여 있지 않다거나(이 경우 값이 하나만 넘어온 것으로 간주됩니다), 값이 적거나 많은 경우에는 다음과 같이 에러가 발생합니다. 123456&gt;&gt;&gt;  %d + %d = %d  % 1, 2, 3TypeError: not enough arguments for format string&gt;&gt;&gt;  %d + %d = %d  % (1, 2)TypeError: not enough arguments for format string&gt;&gt;&gt;  %d + %d = %d  % (1, 2, 3, 4, 5)TypeError: not all arguments converted during string formatting자릿수 지정하기: 문자열 정렬하기: "
    }, {
    "id": 7,
    "url": "http://localhost:4000/gpu-%EC%8B%A4%ED%96%89%EC%8B%9C%EA%B0%84-%EC%B8%A1%EC%A0%95/",
    "title": "[CUDA 7] GPU 실행시간 측정 - cudaEvent",
    "body": "2016/01/15 - GPU에서 실행 시간을 측정할 수 있는 방법은 StopWatchInterface를 사용하는 등 여러 가지가 있지만, NVIDIA에서 공식적으로 제공하는 Programming Guide에서 확인할 수 있는 내용인 cudaEvent를 소개하고자 합니다. 사용하는 방법은 다음과 같습니다. 123456789101112131415161718192021// cudaEvent createcudaEvent_t start, stop;cudaEventCreate(&amp;start);cudaEventCreate(&amp;stop);. . . cudaEventRecord(start, 0);// 실행 시간을 측정할 GPU 코드cudaEventRecord(stop, 0);cudaEventSynchronize(stop);float elapsedTime;cudaEventElapsedTime(&amp;elapsedTime, start, stop);. . . // cudaEvent destroycudaEventDestroy(start);cudaEventDestroy(stop);우선 두 개의 cudaEvent 변수를 생성해주어야 합니다. cudaEvent는 record하는 순간의 timestamp를 저장하는 형식이기 때문에 2개가 필요합니다. 이후 cudaEventRecord() 함수를 이용하여 시작하는 순간과 끝나는 순간의 timestamp를 저장하면 됩니다. 시간은 cudaEventElapsedTime() 함수를 이용하여 받아오는데, 기본적으로 float 형을 사용합니다. 마지막으로 cudaEventDestroy() 함수를 이용하여 cudaEvent를 destroy 해주면 마무리됩니다. "
    }, {
    "id": 8,
    "url": "http://localhost:4000/cpp%EC%97%90%EC%84%9C-cuda-%ED%95%A8%EC%88%98-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/",
    "title": "[CUDA 5.5] cpp에서 CUDA 함수 사용하기",
    "body": "2015/04/07 - 이번 포스팅에서는 cpp에서 CUDA 함수를 사용하는 방법에 대하여 이야기해보겠습니다. 지금껏 . cu 파일만으로 프로젝트를 구성하게 되면 다음과 같은 구조로 나타납니다.  main 함수에서는 kernel 함수로 __global__ 함수를 호출하고, __global__ 함수는 sub 함수로 __device__ 함수를 호출하면서 프로그램이 진행됩니다. 즉, . cu 파일 내에서 main 함수가 있고, __global__ 함수와 __device__ 함수가 존재해 서로를 호출하는 데에 문제가 없었을 것입니다. 하지만 일반적인 프로그램의 경우 cpp(혹은 c)와 CUDA를 혼재해서 사용하게 되고, 그렇게 되면 . cu 파일에 있는 CUDA 함수들을 호출하는 데에 문제가 생깁니다. main 함수는 . cpp 파일에 있고, CUDA 함수는 . cu 파일에 있는 구조가 되기 때문에 그것을 정의해주지 않으면 인식하지 못하기 때문입니다. cpp에서 CUDA 함수를 사용하게 되는 과정을 간단히 구조화하면 다음과 같습니다.  main 함수는 . cpp 파일에 있고, 다른 cpp 함수들도 호출하면서 프로그램이 진행됩니다. 그러다 CUDA 함수를 사용할 경우가 생기면 . cu 파일 내에 정의된 __host__ function을 호출하는 방식으로 CUDA 함수를 사용합니다. __host__ 함수는 필요한 CUDA 함수를 진행하여 결과를 얻어 main 함수, 혹은 cpp 함수로 전달해주는 역할을 합니다. 여기서 중요한 점은 __host__ function과 main 함수는 다르다는 점입니다. main 함수는 __host__ 함수라고 할 수 있지만, 모든 __host__ 함수가 main 함수는 아닙니다. __host__ 함수에 extern  C 라고 표시가 되어 있는데, 이것이 바로 cpp에서 CUDA 함수를 호출할 수 있게 해 주는 문법입니다. 사용하는 방법은 다음과 같습니다. 우선 cpp 파일에 이러이러한 CUDA 함수를 사용할 것이라고 정의하여 줍니다. 일반적으로 header file에 정의하게 되지만, 프로젝트의 사이즈가 크지 않다면 CUDA 함수를 호출하는 부분이 있는 파일에 정의해주면 됩니다. 1extern  C  void cuda_function(int a, int b, . . . );일반적으로 함수를 정의할 때처럼 정의해주면 되지만, 중요한 점은 앞에 extern  C  를 붙여야 한다는 것입니다. 이렇게 정의한 함수를 . cu 파일에서 __host__ 함수로 작성하면 됩니다. 12345678910__global__ void global_function(int a, int b, . . . ) {  . . . }extern  C  void cuda_function(int a, int b, . . . ) {  . . .   global_function&lt;&lt;&lt;blockDim, threadDim&gt;&gt;(a, b, . . . );  checkCudaErrors(cudaThreadSynchronize());  . . . }위 코드는 . cu 파일에 작성되는 코드입니다. extern  C 를 붙인 __host__ 함수는 결국 cpp와 CUDA 함수들을 연결해주는 연결다리 역할을 한다고 볼 수 있습니다. 실제로 사용하는 예는 다음과 같습니다. 제 프로젝트에서 작성한 코드 일부입니다. 12345678910111213141516//kernel Functions//glInputOutput_kernel. cuextern  C  void setupTexture(int iv, int ih, Pixel *data, int bpp, int num);extern  C  void deleteTexture(int num);extern  C  void deleteAllTextures();extern  C  void displayMod(Pixel *data, Pixel *bgData, Pixel *curData, Pixel *diffData, int v, int h, enum showBoxMode mode);// diffImage. cuextern  C  double diffImage(Pixel *bgData, Pixel *curData, Pixel *diffData, unsigned int width, unsigned int height, unsigned int size);// bilateralFilter. cuextern  C  void initTexture(int width, int height, Pixel *image);extern  C  void freeTexture();extern  C  void updateGaussian(float delta, int radius);extern  C  double initBilateralFilterCUDA(float delta, int radius, int width, int height, Pixel *pixels);extern  C  double bilateralFilter(Pixel *pixels, int width, int height, float e_d, int radius, int iterations);123456789__global__ void imageSubtractionGlobal(Pixel *bgData, Pixel *curData, Pixel *diffData, int x) {  int i = blockDim. x * blockIdx. x + threadIdx. x;  diffData[i] = MIN(MAX((bgData[i] - curData[i]), 0. f), 255. f);}extern  C  void diffImage(Pixel *bgData, Pixel *curData, Pixel *diffData, unsigned int width, unsigned int height, unsigned int size) {  imageSubtractionGlobal&lt;&lt;&lt;512, 512&gt;&gt;&gt;(bgData, curData, diffData, width);  checkCudaErrors(cudaThreadSynchronize());}"
    }, {
    "id": 9,
    "url": "http://localhost:4000/cuda-%EB%A9%94%EB%AA%A8%EB%A6%AC-%EC%84%B1%EB%8A%A5-%EC%B5%9C%EC%A0%81%ED%99%94/",
    "title": "[CUDA 5.5] CUDA 메모리 성능 최적화",
    "body": "2015/04/04 - ※ 이 글은 2014년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. CUDA 메모리는 CPU와 비교하면 무척이나 빠른 메모리 액세스 속도를 제공하지만, 최적화된 성능을 발휘하기 위해서는 여러 조건들을 충족시켜야 합니다. CUDA는 수백, 수천 개의 코어에서 DRAM이나 캐시에 있는 데이터를 동시에 읽고, 쓰기 때문에 데이터 병목 현상(bottleneck)이 발생하게 됩니다. 이러한 제약 조건들도 새로운 그래픽 카드가 출시되면서 점차 개선되고 있지만, CUDA 어플리케이션의 성능을 향상시키기 위해서는 이러한 병목 현상을 피하고 이상적인 병렬화를 구현할 필요가 있습니다. 글로벌 메모리 액세스 결합 (Coalescing)CUDA 프로그램에서 구현하는 솔루션과 데이터의 형식에 따라 다양한 글로벌 메모리 액세스 패턴이 나타나게 됩니다. NVIDIA 그래픽 카드의 메모리 전송은 한 번에 512bit를 읽어올 때 최대의 성능을 발휘한다고 알려져 있습니다. 글로벌 메모리를 읽어올 때 최대 bandwidth를 사용할 수 있는 조건이 있는데, 이것을 메모리 결합(Coalescing) 조건이라고 합니다. CUDA에서 결합 조건을 충족할 때와 하지 못했을 때 그래픽 카드의 종류에 따라 최대 10배의 성능 차이가 발생합니다. GeForce 200 시리즈 이후로 글로벌 메모리 액세스 결합 전송 조건이 많이 완화되고, 자동화됨에 따라 이전 시리즈의 그래픽 카드보다 쉽게 개선된 성능을 보입니다. 하지만 가끔 비결합 전송 상태로 동작하여 낮은 성능을 나타낼 때도 있기 때문에 프로그램을 실행하면서 성능을 확인하여 결합 전송이 자동으로 이루어지는지를 확인할 필요가 있습니다. 공유 메모리 뱅크 충돌 (Bank Conflict)공유 메모리는 GPU 프로세서 내부에 장착되어 있어 제대로 사용하면 빠른 속도로 데이터를 처리할 수 있는 CUDA의 큰 장점 중 하나입니다. 공유 메모리의 속도를 저하하는 요인으로는 공유 메모리를 구성하는 메모리 뱅크의 액세스 충돌(Bank Conflic)이 있습니다. 메모리 뱅크(Memory Bank)는 각 뱅크마다 한 번의 GPU 사이클에 한 번 액세스 할 수 있으며, 뱅크의 개수만큼의 스레드가 병렬로 모든 뱅크에 동시에 액세스 할 때 가장 큰 효율을 얻을 수 있습니다. 간단한 섬영르 위해 16KB 공유 메모리와 4개의 뱅크가 있고, 각각의 뱅크는 1KB의 메모리로 이루어져 있다고 가정합시다. 또, 뱅크 0번부터 4byte씩 메모리가 배치되어 16byte 블록이 하나의 열을 이루는 형식이라고 가정하겠습니다. 뱅크 충돌이 없는 공유 메모리 액세스: 위 그림은 뱅크 충돌이 없는 공유 메모리 액세스를 나타냅니다. 공유 메모리에는 글로벌 메모리와 같은 시작 address나 결합 전송 조건은 없지만, 한 스레드 당 하나의 뱅크에 액세스 할 수 있다는 제약이 있습니다. 그림에서는 4개의 스레드가 각각 하나의 뱅크에 액세스하여 뱅크 충돌이 없는 이상적인 패턴을 나타내고 있습니다. 공유 메모리는 글로벌 메모리와 같은 액세스 시작 위치 또는 오름차순 정렬 조건이 없기 때문에 랜덤 액세스에 대해서도 같은 뱅크 액세스만 없으면 효괒거으로 동작하게 됩니다.  즉, 위 그림과 같이 스레드가 어지럽게 공유 메모리에 액세스하더라도 같은 뱅크끼리 겹치는 스레드가 없다면 공유 메모리는 효과적으로 동작합니다. 2-way 뱅크 충돌: 만일 모든 스레드가 한 번에 공유 메모리를 읽거나 쓸 때, 2개의 스레드가 하나의 뱅크에 액세스하려고 하면 뱅크 충돌이 발생하게 됩니다. 2번의 뱅크 충돌이 발생하는 것을 2-way 뱅크 충돌이라고 하는데, 2-way 뱅크 충돌이 발생하면 GPU가 2번의 사이클에 나누어 공유 메모리를 차례로 가져오게 되고, 결국 효율이 절반으로 떨어지게 됩니다.  위 그림은 모든 스레드가 2개씩 하나의 뱅크에 액세스하고 있는 2-way 뱅크 충돌을 나타냅니다. 비슷한 예로 4-way 뱅크 충돌 또한 존재하는데, 4-way 뱅크 충돌이 일어나게 되면 효율은 1/4로 떨어지게 됩니다. CUDA에서 항상 모든 스레드가 2개씩 하나의 뱅크에 액세스해야만이 2-way 뱅크 충돌이 되는 것은 아닙니다. 모든 스레드 중에서 2개의 스레드만 같은 뱅크에 액세스하더라도 결국 GPU는 2번의 사이클에 나누어 공유 메모리에 접근해야 하기 때문에 효율이 절반으로 떨어지는 것은 똑같습니다.  위 그림처럼 모든 스레드가 정렬되어 공유 메모리에 액세스하고 있지만, 스레드 0과 스레드 1이 뱅크 1에 동시에 액세스하고 있는 경우 또한 2-way 뱅크 충돌입니다. 이렇게 프로그램이 구현되어 있으면 아무리 다른 스레드들이 정렬되어 있다고 하여도 전체 효율은 절반으로 떨어집니다. 이것은 워프 단위로 실행하고 워프의 절반 단위로 메모리에 액세스하는 CUDA thread의 특징 때문입니다. 16-way 뱅크 충돌: 16-way 뱅크 충돌은 1차원으로 구성된 스레드-블록(thread-block) 구조에서는 잘 발생하지 않습니다. 하지만 2차원 스레드-블록 구조로 작업을 분할할 때 스레드 인덱스 처리가 제대로 되지 않으면 발생할 수 있습니다. 16-way 뱅크 충돌이 일어나면 2-way 뱅크 충돌이나 4-way 뱅크 충돌과 마찬가지로 각 스레드가 하나의 뱅크에 차례로 액세스하기 때문에 효율이 1/16으로 떨어지게 됩니다. 16-way 뱅크 충돌이 주로 2차원 스레드-블록 구조에서 발생하는 이유는 1차원의 경우 일반적으로 행 방향으로 인덱스를 진행하여 액세스하지만, 2차원에서는 열 방향으로도 인덱스를 진행하는 경우가 생기기 때문입니다.  위 그림과 같이 행 방향으로만 인덱스를 진행할 경우 뱅크 충돌이 발생하지 않고 정상적으로 동작하게 됩니다. 하지만 열 방향으로 인덱스를 진행하면 아래와 같이 뱅크 충돌이 발생할 수 있습니다.  위 그림은 공유 메모리의 뱅크 0에 16개의 스레드가 모두 액세스하여 16-way 뱅크 충돌이 발생하게 되는 상황을 나타냅니다. 이와 같은 뱅크 충돌을 피하기 위해서는 알고리즘을 수정하기 보다는 메모리 할당 공간을 수정하는 것이 좋은 방법입니다.  위 그림은 공유 메모리에 16x17의 배열이 물리적으로 할당된 형태를 나타냅니다. 이와 같은 방법을 메모리 패딩(Memory Padding)이라고 합니다. 위와 같이 공유 메모리를 16x17로 하면 행 방향과 열 방향의 메모리가 동일한 뱅크에 할당되지 않습니다. 약간의 공간을 더 소비함으로써 16-way 뱅크 충돌을 피하고, 뱅크 충돌이 발생했을 때보다 16배의 액세스 속도를 얻을 수 있습니다. 고정 메모리 (Pinned Memory)페이지 락 메모리(Page Lock Memory) 또는 고정 메모리(Pinned Memory)라 불리는 시스템 메모리는 가상 메모리(Virtual Memory) 기술과 관련이 있습니다. 가상 메모리는 컴퓨터에 장착된 RAM의 용량에 한계가 있어 충분하지 않기 때문에 발생하는 메모리 부족 문제를 해결하기 위한 방법으로 개발된 것입니다. 가상 메모리는 컴퓨터와 운영체제에 의해 제어되며 RAM의 부족한 용량을 HDD의 도움을 받아 해결합니다. 운영체제 시스템에 RAM과 HDD의 공간을 이용하여 가상으로 큰 메모리 공간을 페이지 단위로 분할하여 제공하는 것입니다. CUDA 프로그램의 약점 중 하나는 GPU로 계산하기 전에 입력 데이터를 host에서 device로 복사하고, 또 계산된 결과를 device에서 host로 복사하는 과정이 추가되는 것입ㄴ디ㅏ. 이 시간은 기존의 프로그램과 비교했을 때 추가적인 부하로 작용하며, 병목 현상(bottleneck)이 발생할 가능성이 높습니다. 때문에 이 시간을 줄이고자 CUDA 프로그램을 구현할 때 여러 가지 방법을 사용하게 됩니다. 그 중 하나가 바로 가상 메모리 기술의 일부를 제한하고 물리적인 RAM 공간만을 사용하는 것입니다. 가상 메모리를 이용하면 메모리를 사용하기 위해 HDD와 RAM 공간의 페이지 치환이 일어나게 되는데, 이 시간을 줄이고 물리적인 RAM에서 device로 복사하는 것입니다. 이렇게 페이지 치환이 되지 않는 메모리를 페이지 락 메모리(Page Lock Memory) 또는 고정 메모리(Pinned Memory)라고 부르는데, 이는 RAM 공간에만 상주하는 메모리를 의미합니다. 고정 메모리를 사용하면 일반적인 힙(Heap) 메모리 할당 방법보다 약 10~50%의 전송 속도가 향상됩니다. 또 CUDA에서 스트림(Stream, 비동기 함수)를 사용하기 위해서는 고정 메모리를 이용해야만 합니다. 고정 메모리는 CUDA API 함수 호출을 통해 사용할 수 있습니다. 하지만 고정 메모리는 항상 물리적 RAM 공간에 상주하기 때문에 고정 메모리를 너무 많이 사용할 경우 컴퓨터의 가상 메모리가 원활하게 작동하기 어려워 메모리 성능과 전체 시스템의 성능 저하를 가져올 수 있다는 단점이 있습니다. 제로 복사 (Zero-copy)제로 복사(Zero-copy 혹은 MApped Memory) 기능은 단어 뜻 그대로 복사를 하지 않는다는 의미입니다. 대부분의 CUDA 프로그램은 GPU를 사용하기 위해 입력 데이터를 host에서 device로 복사하고, 그 데이터를 처리하여 출력 데이터를 device에서 host로 복사합니다. 이는 데이터 읽기와 계산, 쓰기의 과정이 차례로 실행되며 데이터 전송 시 사용되는 PCI 버스를 한 방향만 사용하게 합니다. 제로 복사는 GPU가 host에 할당된 고정 메모리 영역에 바로 액세스하여 데이터를 읽고 쓰는 작업을 말합니다. PCI 버스를 이용하여 데이터를 전송하는 것은 동일하기 때문에 전송 속도가 빨라지는 것은 아니지만, 메모리에서 읽어들인 데이터를 계산하고 결과값을 메모리에 쓰면 비동기로 양방향 PCI 전송이 진행되기 때문에 그만큼의 성능 향상을 얻을 수 있습니다. 이 방법은 통상적으로 1. 5배에서 2배 가량의 성능 향상 효과가 있다고 알려져 있습니다. 하지만 이런 성능 향상 효과를 얻으려고 맵드 메모리(Mapped Memory)를 사용할 때 글로벌 메모리의 결합 전송(Coalescing)과 동일한 조건을 커널에서 충족시켜야 한다는 제약이 있습니다. 만일 커널에서 작은 크기의 데이터를 많은 횟수로 맵드 메모리에 액세스하게 되면 통상적인 데이터 전송보다 오히려 성능이 떨어지는 효과가 나타납니다. 제로 복사 기능은 GeForce 200 시리즈 이후 계열 GPU부터 지원하며, host 측의 고정 메모리(Pinned System Memory)에 직접 읽고 쓰게 됩니다. CUDA API 함수를 이용하여 맵드 메모리를 할당하는 방법으로 제로 복사를 사용할 수 있습니다. host에 메모리를 할당하고, device 메모리 영역에서 host 측 메모리로 바로 사용할 포인터를 지정해주는 방법으로 사용합니다. 포터블 고정 메모리 (Portable Pinned Memory)고정된 메모리를 이용한 제로 복사는 싱글 스레드 영역에서 유효합니다. 하나의 GPU로 구성된 PC에서는 큰 불편함 없이 고정 메모리를 사용할 수 있지만, 복수의 GPU로 수정된 PC에서는 문제가 생길 수 있습니다. 동시에 2개 이상의 GPU를 구동시키려면 두 개 이상의 host thread를 생성하여 처리하게 되는데, 이 때 하나의 스레드에서 생성한 고정 메모리는 다른 스레드에서 사용할 수 없게 됩니다. 이러면 한정된 시스템 자원인 고정 메모리를 각각의 스레드에서 생성하여 자원을 낭비하는 결과를 낳게 됩니다. 이러한 자원 낭비를 피하고자 사용하는 방법이 바로 포터블 고정 메모리(Portable Pinned Memory)입니다. 포터블 고정 메모리를 사용하기 위해서는 CUDA API 함수에서 옵션을 바꾸어 주는 방법으로 사용할 수 있습니다. 이것으로 CUDA 메모리 성능 최적화 기법에 대한 소개가 끝났습니다. 메모리 성능은 CUDA 프로그램의 성능과 직결된 문제인만큼 다양한 관점에서 최적화 방법을 모색해야 할 것입니다. "
    }, {
    "id": 10,
    "url": "http://localhost:4000/cuda-c-extension-2/",
    "title": "[CUDA 5.0] CUDA C 확장 키워드 (CUDA C Extension) - 변수의 수식어",
    "body": "2015/04/03 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. 저번 포스팅에 이어 CUDA C extension에 관한 설명을 마무리 짓도록 하겠습니다. 변수의 수식어변수의 수식어들은 메모리 영역에 따라서 구분되어 집니다. 즉, 변수가 위치하는 메모리의 위치가 어디냐에 따라 __device__, __constant__, __shared__ 세 가지로 나뉘어집니다. 메모리에 대해서는 이후 포스팅에서 따로 자세히 설명하도록 하고, 이번 포스팅에서는 간단하게만 언급하도록 하겠습니다. __device__: 함수의 수식어인 __device__와는 다르므로 꼭 구분해 주셔야 합니다. __device__ 변수는 글로벌 메모리 영역에 할당되어 프로그램이 종료될 때까지 유효하게 됩니다. __device__ 변수에는 모든 thread가 접근할 수 있고, host에서는 API 함수를 통해 읽기와 쓰기가 가능합니다. 1234567891011121314151617181920212223#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;__device__ int d_sum;__global__ void add(int a, int b) {  d_sum = a + b;}__host__ int main() {  int h_sum = 0;  cudaMemset(&amp;d_sum, 0, sizeof(int));  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7);  cudaMemcpyFromSymbol(&amp;h_sum, d_sum, sizeof(int), 0, cudaMemcpyDeviceToHost);  printf( 2 + 7 = %d\n , h_sum);  return 0;}__device__ 변수는 위와 같이 cudaMemcpyFromSymbol이라는 함수를 통해 host 메모리에 불러올 수 있습니다. 여기서 주의하실 점은 CUDA 5. 0부터 바뀐 점으로, 이전 버전들과는 symbol을 다른 방식으로 사용하여야 한다는 점입니다. 1  cudaMemcpyFromSymbol(&amp;h_sum,  d_sum , sizeof(int), 0, cudaMemcpyDeviceToHost);이전 방식으로 cudaMemcpyFromSymbol 함수를 호출하면 위와 같이 호출하여야 합니다. 즉, 이전 버전들에서는 symbol을 character string으로 사용하였다면, CUDA 5. 0부터는 symbol을 direct로 사용할 수 있도록 바뀌었습니다. 대신 이전 버전들과 같은 방법으로는 사용할 수 없습니다. 하지만 CUDA 5. 0에서도 symbol을 direct로 사용하였을 때, 빨간 밑줄이 그어지며 다음과 같은 error가 발생합니다만, 실제로 실행시켰을 때는 아무런 문제가 없습니다. 추후에 업데이트 되면서 사라질 문제가 될 것 같습니다.  __constant__: __constant__ 변수는 그 이름에서도 알 수 있듯이 상수 메모리, 즉 constant memory 영역에 할당되어 프로그램이 종료될 때까지 유효한 변수입니다. 모든 thread에서 접근이 가능하지만, __device__ 변수와는 다르게 __constant__ 변수는 읽기만 가능합니다. 대신 host에서 cudaMemcpyToSymbol 함수를 통해 값을 쓸 수 있도록 되어 있습니다. 1234567891011121314151617#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;__constant__ int d_sum = 0;int main() {  int h_sum1 = 9;  int h_sum2 = 0;  cudaMemcpyToSymbol(d_sum, &amp;h_sum1, sizeof(int), 0, cudaMemcpyHostToDevice);  cudaMemcpyFromSymbol(&amp;h_sum2, d_sum, sizeof(int), 0, cudaMemcpyDeviceToHost);  printf( h_sum2 = %d\n , h_sum2);  return 0;}여기서도 주의하셔야 할 점은 CUDA 5. 0부터 cudaMemcpyToSymbol의 쓰임 역시 바뀌었다는 점입니다. 위에서 __device__ 변수를 설명하면서 언급하였던 cudaMemcpyFromSymbol 함수와 마찬가지로 symbol을 direct로 사용하도록 바뀌었습니다. 이전 버전들에서는 다음과 같이 사용하였지만, CUDA 5. 0부터는 아래 방식을 사용할 수 없습니다. 1  cudaMemcpyToSymbol( d_sum , &amp;h_sum1, sizeof(int), 0, cudaMemcpyHostToDevice);즉, 위와 같이 symbol을 character string으로 사용할 수 없습니다. __shared__: __shared__ 변수 역시 그 이름에서 알 수 잇듯 공유 메모리 영역에 할당됩니다. 다만 다른 변수들과는 달리 실행 중인 thread block 상에서만 유효하다는 것이 특징입니다. __device__ 변수나 __constant__ 변수가 프로그램이 종료될 때까지 유효한 것과는 다릅니다. 또, __shared__ 변수는 block 내의 thread는 접근하여 읽고 쓰는 것이 가능하도록 되어 있습니다. 12345678910111213141516171819202122232425#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;__global__ void add(int a, int b, int *c) {  __shared__ int sum;  sum = a + b;  *c = sum;}int main() {  int c;  int *dev_c;  cudaMalloc((void**)&amp;dev_c, sizeof(int));  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);  cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);  printf( 2 + 7 = %d\n , c);  cudaFree(dev_c);  return 0;}위는 __shared__ 변수를 사용한 예시입니다. 예시에서는 단순하게 하나의 block에 하나의 thread만이 실행되는 코드이지만, 많은 thread가 실행되는 코드라면 __shared__ 변수를 유용하게 사용할 수 있을 것입니다. 이것으로 CUDA C Extension에 대한 설명을 끝내도록 하겠습니다. 메모리에 대한 상세한 설명이나 CUDA의 다른 부분에 대해서는 이후 포스팅에서 더욱 자세히 다뤄보겠습니다. "
    }, {
    "id": 11,
    "url": "http://localhost:4000/cuda-c-extension-1/",
    "title": "[CUDA 5.0] CUDA C 확장 키워드 (CUDA C Extension) - 함수의 수식어",
    "body": "2015/04/03 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. 이번 포스팅에서는 CUDA C Extension, 즉 CUDA에서 확장된 키워드들에 대하여 소개하고자 합니다. 예제 코드를 보면 __global__과 같은 키워드들을 쉽게 발견할 수 있을 것입니다. 이러한 키워드들이 어떤 의미이며 무슨 역할을 하는지 알아야 보다 효율적인 프로그래밍이 가능할 것입니다. 함수의 수식어함수의 수식어들은 어디서 호출할 수 있느냐와 어디서 실행되느냐에 따라 나뉩니다. __global__, __device__, __host__, __device__ __host__ 이렇게 총 4가지의 경우가 가능합니다. __global__: 디바이스에서 실행되는 함수를 뜻합니다. 여기서 device란 이전 포스팅에서도 언급 했듯이 GPU를 뜻합니다. __global__로 수식된 함수는 host에서 호출할 수는 있어도 device에서 호출할 수는 없습니다. 대신 device로 실행하는 커널 함수 지정에 사용할 수 있습니다. 다음은 __global__로 수식한 함수의 간단한 예입니다. 1234567891011121314151617181920212223#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio . h&gt;;__global__ void add(int a, int b, int *c) {  *c = a + b;}int main() {  int c;  int *dev_c;  cudaMalloc((void**)&amp;dev_c, sizeof(int));  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);  cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);  printf( 2 + 7 = %d\n , c);  cudaFree(dev_c);  return 0;}위와 같이 return type은 항상 void 형이어야 하며, 다른 return type은 가질 수 없습니다. 이것은 조금만 생각해보면 쉽게 그 이유를 알 수 있습니다. 지금의 예에서는 하나의 커널 함수만이 실행되었지만, 실제로는 수천, 수만 개의 커널 함수가 한꺼번에 실행될 것입니다. 만약 __global__ 함수의 리턴 타입이 void가 아니라면 수천, 수만 개의 커널 함수에서 제각각 return 값을 host로 넘겨주게 될 것입니다. 그러한 문제를 막기 위해 아예 void 형이 아닌 다른 return type을 가질 수 없도록 한 것입니다. 또, 함수의 호출 시에 &lt;&lt;&lt; block의 개수, thread의 개수 &gt;&gt;&gt;의 형식으로 block과 thread의 개수를 지정해 줄 수 있습니다. __global__ 함수는 device에서 실행되는 함수이지만 device에서는 호출할 수 없습니다. 즉, 재귀호출이 불가능합니다. 이것 또한 이 함수가 수만 개가 한꺼번에 실행되는 커널 함수라는 것을 생각해보면 그 이유를 쉽게 알 수 있습니다. 또한 함수 내에 static 변수를 가질 수 없으며, 가변형 인수를 가질 수 없는 등의 제약 사항이 존재합니다. 가변형 인수를 가질 수 없다는 것은 다음과 같은 식으로 함수를 호출하는 코드는 불가능하다는 것을 뜻합니다. 1  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(int a, int b, dev_c);또한 __global__ __host__와 같은 용법으로 쓰일 수 없고, 공유 메모리를 이용하며 256 바이트까지의 인수를 사용할 수 있습니다. __device__: 위의 __global__과 마찬가지로 device에서 실행되는 함수를 뜻합니다. 하지만 __global__과는 다르게 host에서 호출이 불가능하고, device에서만 호출이 가능합니다. 즉, __global__ 함수가 실행되었을 때 device 내에서 실행되는 서브 함수로 사용됩니다. device에서 실행되고 device에서 호출되기 때문에 재귀 호출이 가능하지 않느냐고 생각할 수도 있지만 마찬가지로 재귀호출은 할 수 없습니다. 1234567__device__ int subAdd(int a, int b) {  return a + b;}__global__ void add(int a, int b, int *c) {  *c = subAdd(a, b);}__global__에서 예시로 들었던 add 함수의 코드를 조금만 바꾼 __device__ 함수의 예시입니다. 실행시켜 보면 똑같은 결과값이 나오는 것을 알 수 있습니다. __global__ 함수는 device 내에서 실행되는 함수이기 때문에 __device__ 함수를 호출할 수 있습니다. 하지만 host에서는 호출할 수 없기 때문에 다음과 같은 호출은 불가능합니다. 12345678910111213141516#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;__device__ int subAdd(int a, int b) {  return a + b;}int main() {  int c;  c = subAdd(2, 7);  print( 2 + 7 = %d\n , c);  return 0;}위 코드를 실행시키면 다음과 같은 에러가 발생합니다. 1error : calling a __device__ function( subAdd ) from a __host__ function( main ) is not allowed즉, __host__ 함수인 main 함수에서 __device__ 함수인 subAdd 함수를 호출할 수 없다는 것입니다. 추가적으로, __device__ 함수 역시 __global__ 함수와 마찬가지로 static 변수를 함수 내에 가질 수 없고, 가변형 인수를 가질 수 없습니다. __host__: __host__ 함수는 위에서 언급했던 __global__이나 __device__ 함수와는 실행되는 위치부터가 다릅니다. host에서 실행되며, host에서만 호출할 수 있고, device에서는 호출할 수 없습니다. main 함수가 그 대표적인 예입니다. main 함수를 통해서 알 수 있드시, __global__, __device__, __host__ 등의 키워드가 지정되지 않은 경우에는 __host__를 지정한 것과 동일한 효과를 지닙니다. 123456789101112131415161718192021222324252627#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;;__device__ int subAdd(int a, int b) {  return a + b;}__global__ void add(int a, int b, int *c) {  *c = subAdd(a, b);}__host__ int main() {  int c;  int *dev_c;  cudaMalloc((void**)&amp;dev_c, sizeof(int));  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);  cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);  printf( 2 + 7 = %d\n , c);  cudaFree(dev_c);  return 0;}위의 코드처럼 main 함수를 __host__로 지정해주어도 아무런 문제 없이 잘 실행이 됩니다. 이는 main 함수가 __host__ 함수이기 때문이며, 어떤 함수인지 지정해주지 않았을 때는 default로 __host__로 지정되기 때문입니다. __host__ 수식어는 __global__ 수식어와 동시에 사용할 수는 없지만, __device__ 수식어와는 함께 사용할 수 있습니다. 바로 __device__ __host__와 같은 방법으로 사용하는 것인데요. 이에 대해서는 아래에서 따로 설명하도록 하겠습니다. __device__ __host__: __host__ 수식어와 __device__ 수식어를 동시에 사용한 경우입니다. 이 경우 host와 device 양쪽에서 모두 사용할 수 있는 함수로 작성할 수 있습니다. 1234567891011121314151617#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;;__device__ __host__ int subAdd(int a, int b) {  return a + b;}int main() {  int c;  c = subAdd(2, 7);  printf( 2 + 7 = %d\n , c);  return 0;}위 코드를 실행시키면 역시나 아무런 문제 없이 잘 동작합니다. 이는 subAdd 함수가 host와 device 모두에서 사용할 수 있는 함수이기 때문입니다. 이러한 수식어를 사용하는 것이 무척이나 편리한 경우가 가끔 생기는데, host와 device 모두에서 호출하는 간단한 계산 같은 것을 __device__ __host__ 함수로 지정하여 사용하는 경우가 있습니다. 같은 내용의 함수를 device 용, host 용으로 두 개나 만들지 않고, 하나의 함수로 해결하는 것입니다. 그 때문에 device와 host 모두에서 사용가능한 함수가 필요했고, 이 함수는 host와 device 각각 호출이 가능하며, 호출된 곳(host라면 host, device라면 device)에서 실행될 필요가 있었습니다. 따라서 __global__ 키워드는 제외되고, __device__ __host__와 같은 형식으로 device와 host 모두에서 사용 가능하도록 만들어진 것입니다. 포스팅의 내용이 길어서 CUDA C 확장 키워드에 대해서 다음 포스팅에서 이어서 설명하도록 하겠습니다. 다음 포스팅에서는 변수의 수식어에 대해 이야기하도록 하겠습니다. "
    }, {
    "id": 12,
    "url": "http://localhost:4000/cuda-syntax-device/",
    "title": "[CUDA 5.0] CUDA syntax를 이용하여 device 정보 불러오기",
    "body": "2015/04/02 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. 본격적인 CUDA 코딩에 앞서 CUDA syntax를 이용하여 device의 정보를 불러오는 방법에 대해 소개하려고 합니다. 여기서 말하는 device란 CUDA acceleration(CUDA 가속)을 지원하는 GPU를 뜻합니다. 아래의 코드는 CUDA syntax를 이용하여 device의 정보를 불러와 출력하는 내용입니다. 123456789101112131415161718192021222324252627#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;int main() {  int i;  cudaDeviceProp prop;  int count;  cudaGetDeviceCount(&amp;count);  for (i = 0 ; i &lt; count ; i++) {    cudaGetDeviceProperties(&amp;prop, i);    printf( -- %d번째 디바이스 --\n , i+1);    printf(  (1) 장치 이름 : %s\n , prop. name);    printf(  (2) Clock Rate : %d\n , prop. clockRate);    printf(  (3) 전역 메모리 용량 : %ld\n , prop. totalGlobalMem);    printf(  (4) 상수 메모리 용량 : %ld\n , prop. totalConstMem);    printf(  (5) Register per block : %d\n , prop. regsPerBlock);    printf(  (6) Max Grid Size : %d\n , prop. maxGridSize);    printf(  (7) Max Thread Dimension : %d\n , prop. maxThreadsDim);    printf(  (8) Max Thread per block : %d\n , prop. maxThreadsPerBlock);  }  return 0;}CUDA는 cudaDeviceProp이라는 구조체 형식에 device들의 정보를 저장하게 됩니다. 이를 이용하면 device의 다양한 정보를 불러올 수 있습니다. 아래는 위 코드를 실행시킨 결과입니다.  출력된 결과를 살펴보면, GeForce GT 750M이라는 하나의 device를 사용 중이며, clock rate나 메모리 용량이 얼마인지 알 수 있습니다. cudaDeviceProp은 이외에도 다양한 정보를 제공합니다. 이러한 데이터를 잘 활용하면 효과적인 CUDA 코딩을 할 수 있을 것입니다. 그러면 위 코드를 자세히 살펴봅시다. 1  cudaDeviceProp prop;Device property의 출력을 위해 구조체를 생성한 것입니다. 위에서 잠깐 언급했듯이 CUDA는 device의 정보를 구조체 형식에 저장합니다. cudaDeviceProp 구조체는 driver_types. h 파일에 선언되어 있으며, 이러한 header file들은 CUDA project를 생성하면 외부 종속성 폴더에 추가되도록 되어 있습니다. 아래는 cudaDeviceProp 구조체의 선언 부분입니다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * CUDA device properties */struct __device_builtin__ cudaDeviceProp{  char  name[256];         /**&lt; ASCII string identifying device */  size_t totalGlobalMem;       /**&lt; Global memory available on device in bytes */  size_t sharedMemPerBlock;     /**&lt; Shared memory available per block in bytes */  int  regsPerBlock;        /**&lt; 32-bit registers available per block */  int  warpSize;          /**&lt; Warp size in threads */  size_t memPitch;          /**&lt; Maximum pitch in bytes allowed by memory copies */  int  maxThreadsPerBlock;     /**&lt; Maximum number of threads per block */  int  maxThreadsDim[3];      /**&lt; Maximum size of each dimension of a block */  int  maxGridSize[3];       /**&lt; Maximum size of each dimension of a grid */  int  clockRate;         /**&lt; Clock frequency in kilohertz */  size_t totalConstMem;       /**&lt; Constant memory available on device in bytes */  int  major;           /**&lt; Major compute capability */  int  minor;           /**&lt; Minor compute capability */  size_t textureAlignment;      /**&lt; Alignment requirement for textures */  size_t texturePitchAlignment;   /**&lt; Pitch alignment requirement for texture references bound to pitched memory */  int  deviceOverlap;       /**&lt; Device can concurrently copy memory and execute a kernel. Deprecated. Use instead asyncEngineCount. */  int  multiProcessorCount;    /**&lt; Number of multiprocessors on device */  int  kernelExecTimeoutEnabled;  /**&lt; Specified whether there is a run time limit on kernels */  int  integrated;         /**&lt; Device is integrated as opposed to discrete */  int  canMapHostMemory;      /**&lt; Device can map host memory with cudaHostAlloc/cudaHostGetDevicePointer */  int  computeMode;        /**&lt; Compute mode (See ::cudaComputeMode) */  int  maxTexture1D;        /**&lt; Maximum 1D texture size */  int  maxTexture1DMipmap;     /**&lt; Maximum 1D mipmapped texture size */  int  maxTexture1DLinear;     /**&lt; Maximum size for 1D textures bound to linear memory */  int  maxTexture2D[2];      /**&lt; Maximum 2D texture dimensions */  int  maxTexture2DMipmap[2];   /**&lt; Maximum 2D mipmapped texture dimensions */  int  maxTexture2DLinear[3];   /**&lt; Maximum dimensions (width, height, pitch) for 2D textures bound to pitched memory */  int  maxTexture2DGather[2];   /**&lt; Maximum 2D texture dimensions if texture gather operations have to be performed */  int  maxTexture3D[3];      /**&lt; Maximum 3D texture dimensions */  int  maxTextureCubemap;     /**&lt; Maximum Cubemap texture dimensions */  int  maxTexture1DLayered[2];   /**&lt; Maximum 1D layered texture dimensions */  int  maxTexture2DLayered[3];   /**&lt; Maximum 2D layered texture dimensions */  int  maxTextureCubemapLayered[2];/**&lt; Maximum Cubemap layered texture dimensions */  int  maxSurface1D;        /**&lt; Maximum 1D surface size */  int  maxSurface2D[2];      /**&lt; Maximum 2D surface dimensions */  int  maxSurface3D[3];      /**&lt; Maximum 3D surface dimensions */  int  maxSurface1DLayered[2];   /**&lt; Maximum 1D layered surface dimensions */  int  maxSurface2DLayered[3];   /**&lt; Maximum 2D layered surface dimensions */  int  maxSurfaceCubemap;     /**&lt; Maximum Cubemap surface dimensions */  int  maxSurfaceCubemapLayered[2];/**&lt; Maximum Cubemap layered surface dimensions */  size_t surfaceAlignment;      /**&lt; Alignment requirements for surfaces */  int  concurrentKernels;     /**&lt; Device can possibly execute multiple kernels concurrently */  int  ECCEnabled;         /**&lt; Device has ECC support enabled */  int  pciBusID;          /**&lt; PCI bus ID of the device */  int  pciDeviceID;        /**&lt; PCI device ID of the device */  int  pciDomainID;        /**&lt; PCI domain ID of the device */  int  tccDriver;         /**&lt; 1 if device is a Tesla device using TCC driver, 0 otherwise */  int  asyncEngineCount;      /**&lt; Number of asynchronous engines */  int  unifiedAddressing;     /**&lt; Device shares a unified address space with the host */  int  memoryClockRate;      /**&lt; Peak memory clock frequency in kilohertz */  int  memoryBusWidth;       /**&lt; Global memory bus width in bits */  int  l2CacheSize;        /**&lt; Size of L2 cache in bytes */  int  maxThreadsPerMultiProcessor;/**&lt; Maximum resident threads per multiprocessor */};위와 같이 선언되어 있는데, 각각 어떤 것을 의미하는지는 각 항목마다 설명이 주석처리 되어 있으므로 자세한 설명은 하지 않겠습니다. 앞서 출력해 보았던 내용 이외에도 엄청나게 많은 정보들을 저장하고 있지만, 가장 많이 쓰이게 될 몇 가지 정보들만 출력해 보았습니다. 12  int count;  cudaGetDeviceCount(&amp;count);device 장치의 개수를 획득하는 함수입니다. int 형 변수인 count를 만들고, 그것의 주소값을 argument로 넘겨주게 됩니다. cudaGetDeviceCount 함수는 cuda_runtime_api. h에 다음과 같이 정의되어 있습니다. 1extern __host__ __cudart_builtin__ cudaError_t CUDARTAPI cudaGetDeviceCount(int *count);parameter로 count의 포인터를 넘겨 받기 때문에 호출 시 argument의 사용에 주의해 주셔야 합니다. 함수의 이름에서 알 수 있다시피 count 변수에는 device의 개수 값이 들어갑니다. CUDA 뿐만이 아니라 다른 언어나 tool을 공부할 때에도 마찬가지로, 어떤 함수를 사용할 때 그것이 어떻게 정의되어 있는지 내부를 공부하는 것은 무척이나 많은 도움이 됩니다. 특히나 CUDA는 C 기반으로 짜여져 있는데다 주석도 잘 달려 있어 공부하기 편리합니다. 이렇게 CUDA syntax를 이용하여 device의 정보를 출력하는 방법에 대해 알아보았습니다. 이후 포스팅에서 CUDA 병렬 프로그래밍에 대해 더 자세히 알아보도록 하겠습니다. "
    }, {
    "id": 13,
    "url": "http://localhost:4000/cuda-syntax-highlighting/",
    "title": "[CUDA 5.0] CUDA Syntax Highlighting 설정하기",
    "body": "2015/04/01 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. VS에서 CUDA 코드를 작성하면 CUDA Syntax Highlighting은 물론이고 기본적인 C/C++ 문법마저도 Syntax Highlighting이 되지 않아 코드를 작성하기 무척이나 번거롭고 힘들었을 것입니다. 따라서, 이번 포스팅에서는 CUDA Syntax Highlighting 방법에 대해 소개하려 합니다. 이전 버전들과는 방법이 다르기 때문에, 다른 버전을 사용 중이라면 적용되지 않을 수도 있다는 점을 염두에 두시길 바랍니다. 우선 VS를 켜고, 상단 메뉴 바에서 도구 -&gt; 옵션으로 들어갑니다. 창이 하나 나타나는데, 여기서 프로젝트 및 솔루션 -&gt; VC++ 프로젝트 설정으로 들어가면 아래의 창 같은 화면이 뜹니다. 이 중 포함할 확장명에 . cu; cuh;를 추가합니다. 확장자명끼리의 구분은 ;로 구분하게 됩니다. . cu 파일은 CUDA source file이고, . cuh 파일은 CUDA header file입니다.  확장명에 추가했으면 이제 . cu와 . cuh를 C++ 편집 환경으로 설정해 줄 차례입니다. 옵션 창에서 텍스트 편집기 -&gt; 파일 확장명으로 들어가면, 아래와 같은 창이 나타납니다. 여기에 확장명 . cu, 편집기 Microsoft Visual C++을 선택하고 적용하면 됩니다. . cuh도 마찬가지 방법으로 적용해 줍니다.  이제 C:\ProgramData\NVIDIA Corporation\CUDA Samples\v5. 0\doc\syntax_highlighting\visual_studio_8 폴더로 들어가보면 usertype. dat 파일이 있을 것입니다. 이 파일을 C:\Program Files\Microsoft Visual Studio 10. 0\Common7\IDE 폴더에 복사해 넣으면 됩니다. 주소는 32bit 기준이므로, 64bit라면 Program Files (x86) 폴더에서 찾아 복사해 넣도록 합니다.  이것으로 CUDA Syntax Highlighting 준비가 모두 끝났습니다. VS를 다시 시작하거나 아니면 프로젝트를 다시 열면 문법에 맞는 색깔로 설정된 C/C++ 코드를 볼 수 있을 것입니다. 참고로, CUDA Syntax Highlighting을 위해서는 아래의 두 줄을 추가로 입력해 주어야지만 정상적으로 표현이 됩니다. 12#include  cuda_runtime. h #include  device_launch_parameters. h 이 두 줄은 모두 CUDA Project를 생성하면 만들어지는 kernel. cu에 포함되어 있습니다.  위는 정상적으로 CUDA Syntax Highlighting이 적용된 코드입니다. __global__이나 threadIdx와 같은 CUDA 문법들에도 highlighting이 적용된 것을 확인할 수 있습니다. 참고로 위 화면에서는 다른 테마가 적용되어 있으므로, 실제로 highlighting을 적용했을 때 다르게 보일 수 있습니다. "
    }, {
    "id": 14,
    "url": "http://localhost:4000/cuda-%EC%98%88%EC%A0%9C-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/",
    "title": "[CUDA 5.0] CUDA 예제 실행하기",
    "body": "2015/03/31 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. CUDA 5. 0을 설치하고, 리부팅을 하고 나면 NVIDIA CUDA Samples Browser v5. 0 아이콘이 생겼을 것입니다. 이름만으로도 어떤 프로그램인지 감이 오시나요? CUDA 5. 0부터는 Installer에 samples 또한 포함이 되어 있다고 저번 포스팅에서 언급하였습니다. 이 프로그램이 바로 설치와 같이 다운 받은 예제 파일들을 찾아보고, 실행해 볼 수 있는 프로그램입니다. 한 번 실행해 봅시다.  실행하면 보이는 바와 같이 다양한 샘플들을 찾아볼 수 있고, 실행시켜 볼 수도 있습니다. 이 샘플들을 실행시켰을 때, 아무 무리 없이 잘 돌아가면 설치가 제대로 되었다는 뜻입니다. 만약 실행이 되지 않는다면, 컴퓨터에 설치되어 있는 GPU가 CUDA 가속을 지원하는지를 확인하고, 또 NVIDIA 그래픽 드라이버가 최신 버전인지를 확인해 주세요. 이 중 CUDA N-Body Simulation을 실행시켜 봅시다. N-Body가 무엇인지 몰라도 어떤 프로그램인지는 그래픽으로 시뮬레이션해주기 때문에 알아보기 쉽습니다. 실행하는 방법은 오른쪽 편에 작은 글씨로 된 Run을 누르면 됩니다. 실행하면 다음과 같은 창 하나가 뜹니다. 이 창에서는 프로그램에 대한 간단한 설명 등과 함께 맨 아래쪽에 보면 어떤 device를 사용하고 있는지에 대한 정보도 같이 볼 수 있습니다. simulation을 위해 하나의 device를 사용하였고, 그 device는 GeForce 310M이라는 정보가 뜹니다. 이 정보는 각자 사용하는 GPU에 따라 다르게 나타날 것입니다.  그리고 하나 더 뜨는 창에서는 다음과 같이 N-Body Simulation이 이루어집니다. 현재 시뮬레이션 되고 있는 상태에 대해서는 화면 위쪽에 나타나게 되고, 화면 전체에 N-Body Simulation이 약간의 끊김이 있기는 하지만 빠르고 매끄럽게 진행되는 것을 확인할 수 있습니다. 심지어 310M이라는 낮은 사양의 GPU에서도 말이죠.  NVIDA CUDA Samples Browser에서는 이러한 N-Body Simulation 이외에도 다양한 예제들을 실행시켜 볼 수 있습니다. 그리고 이러한 예제들의 코드 역시 같이 다운받아져 있는데, 이 코드들은 C:\ProgramData\NVIDIA Corporation\CUDA Samples\v5. 0 폴더에 잘 정리되어 있습니다. ProgramData 폴더는 숨겨져 있는 폴더이므로 C 드라이브에 들어갔는데 폴더가 없다고 당황하지 않으셔도 됩니다. 위 주소로 들어가보면 다음과 같이 잘 정리된 CUDA 예제들의 코드를 확인하고, 직접 실행시켜 볼 수 있습니다.  아까 위에서 실행시켜 보았던 N-Body Simulation은 5_Simulation 폴더에 nbody라는 이름으로 들어가 있습니다. VS에서 실행시켜 보면 앞서 실행시켰던 것과 같은 결과가 나오는 것을 확인할 수 있습니다. 예제 파일들은 간단한 것부터 복잡하고 어려운 계산이나 그래픽을 요하는 것까지 다양하게 제공되므로, 예제 파일을 분석하며 공부하는 것도 많은 도움이 될 것입니다. CUDA를 공부하면 C/C++로 이미 만들어져 있는 프로그램을 포팅하는 것을 주로 하게 되고, 어떻게 최적화를 하느냐에 따라 같은 내용을 실행시키더라도 성능이 확연하게 달라질 수 있습니다. 따라서 이미 잘 짜여져 있는 성능 좋은 코드를 많이 보는 것이 공부에 도움이 될 것입니다. CUDA Project는 C/C++ Project를 그대로 이용해도 상관 없으나, VS에서는 CUDA를 설치하면 다음과 같이 CUDA 5. 0 Runtime Project를 바로 생성할 수 있도록 해 줍니다.  CUDA 5. 0 Rumtime Project를 생성하면 따로 무언가를 설정할 필요 없이 바로 컴파일이나 빌드를 할 수 있도록 되어 있습니다. 생성하면 kernel. cu라는 소스 파일 하나가 공통적으로 들어가 있는데요. 여기에는 1차원 array를 더하는 내용의 코드가 포함되어 있습니다. 무척 간단한 코드로 실행시켜 보면 다음과 같은 결과가 출력됩니다.  이것으로 CUDA 예제를 가능한 모든 방법을 동원하여 실행하여 보았습니다. CUDA는 아직 한글로 번역된 책이 많이 없기 때문에 이미 만들어져 있는 예제들을 보면서 실행시켜 보고, 스스로 분석하고, 다른 코드를 CUDA로 포팅해보는 연습을 하다 보면 실력이 많이 느는 것을 확인할 수 있을 것입니다. 자, 이렇게 CUDA 5. 0을 사용하여 코딩할 준비가 모두 끝났습니다. 다음 포스팅에서는 위 화면에 보이는 바와 같이 CUDA Syntax Highlighting 하는 방법에 대해서 이야기하도록 하겠습니다. "
    }, {
    "id": 15,
    "url": "http://localhost:4000/cuda-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0/",
    "title": "[CUDA 5.0] CUDA 설치하기",
    "body": "2015/03/30 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. CUDA 5. 0은 이전 버전들과는 달리 설치가 매우 간편해진 것이 특징입니다. NVIDIA 사이트에서 CUDA ZONE을 들어가면 영어로 된 developer zone이 나오는데, 여기서 CUDA Download를 클릭해 들어가면 다음과 같은 페이지가 뜹니다. 참고로, NVIDIA Korea 사이트에서는 한글 번역을 지원해주지만 developer zone은 한글 번역을 지원해주지 않습니다. 또, 한국 사이트에서는 낮은 버전의 CUDA를 다운받게 되므로 꼭 원래 사이트에 들어가서 다운 받아 주세요.  여기서 Desktop/Notebook의 OS 등에 맞는 파일을 클릭하여 다운 받을 수 있습니다. CUDA 5. 0부터는 CUDA Toolkit과 SDK code samples, developer driver를 모두 한꺼번에 다운 받아 설치할 수 있어 무척이나 간편하게 설치할 수 있게 되어 있습니다. 다운 받은 installer를 실행하면 설치가 끝납니다. 설치가 끝나면 컴퓨터를 리부팅해야 CUDA를 사용할 수 있습니다. 자신의 GPU가 CUDA 가속을 지원하는 지에 대해서는 CUDA ZONE에서 CUDA GPUs를 들어가면 확인할 수 있습니다. Tesla, Quadro, NVS, GeForce 순으로 나와 있습니다. 현재는 대부분의 GPU들이 CUDA 가속을 지원합니다.  한 가지 더. CUDA를 사용하기 위해서는 그래픽 드라이버가 최신 버전이어야 합니다. NVIDIA 사이트에서 다운 받을 수 있으니 최신 버전인지를 확인하고 업데이트 하도록 합시다. 혹시 이후에 실행을 시켰는데 되지 않는다면 그래픽 드라이버가 최신 버전이 아니기 때문일 수도 있습니다. 자, 이렇게 CUDA 5. 0을 설치하여 사용할 준비가 끝났습니다. CUDA 5. 0에서는 다양한 예제 파일들을 같이 다운 받았기 때문에 그것들을 실행시켜 볼 수 있습니다. 예제 파일의 실행에 대해서는 다음 포스팅 때 이야기하도록 하겠습니다. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});