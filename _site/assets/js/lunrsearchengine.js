
var documents = [{
    "id": 0,
    "url": "http://localhost:4000/404.html",
    "title": "404",
    "body": "404 Page does not exist!Please use the search bar at the top or visit our homepage! "
    }, {
    "id": 1,
    "url": "http://localhost:4000/categories",
    "title": "Categories",
    "body": ""
    }, {
    "id": 2,
    "url": "http://localhost:4000/",
    "title": "Home",
    "body": "      Featured:                                                                                                                                                                                                                       [CUDA 5. 0] CUDA Syntax Highlighting 설정하기                              :               ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                                                                                                                         Chloe Jungah Kim                                    01 Apr 2015                                                                                                                                                                                                                                                                                  [CUDA 5. 0] CUDA 예제 실행하기                              :               ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                                                                                                                         Chloe Jungah Kim                                    31 Mar 2015                                                                                                                                                                                                                                                                                  [CUDA 5. 0] CUDA 설치하기                              :               ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                                                                                                                         Chloe Jungah Kim                                    30 Mar 2015                                                                                      All Stories:                                                                                                     [CUDA 5. 0] CUDA C 확장 키워드 (CUDA C Extension) - 함수의 수식어              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                03 Apr 2015                                                                                                                    [CUDA 5. 0] CUDA syntax를 이용하여 device 정보 불러오기              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                02 Apr 2015                                                                                                                    [CUDA 5. 0] CUDA Syntax Highlighting 설정하기              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                01 Apr 2015                                                                                                                    [CUDA 5. 0] CUDA 예제 실행하기              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                31 Mar 2015                                                                                                                    [CUDA 5. 0] CUDA 설치하기              :       ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. :                                                                               Chloe Jungah Kim                30 Mar 2015                            "
    }, {
    "id": 3,
    "url": "http://localhost:4000/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 4,
    "url": "http://localhost:4000/cuda-c-extension-1/",
    "title": "[CUDA 5.0] CUDA C 확장 키워드 (CUDA C Extension) - 함수의 수식어",
    "body": "2015/04/03 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. 이번 포스팅에서는 CUDA C Extension, 즉 CUDA에서 확장된 키워드들에 대하여 소개하고자 합니다. 예제 코드를 보면 __global__과 같은 키워드들을 쉽게 발견할 수 있을 것입니다. 이러한 키워드들이 어떤 의미이며 무슨 역할을 하는지 알아야 보다 효율적인 프로그래밍이 가능할 것입니다. 함수의 수식어함수의 수식어들은 어디서 호출할 수 있느냐와 어디서 실행되느냐에 따라 나뉩니다. __global__, __device__, __host__, __device__ __host__ 이렇게 총 4가지의 경우가 가능합니다. __global__: 디바이스에서 실행되는 함수를 뜻합니다. 여기서 device란 이전 포스팅에서도 언급 했듯이 GPU를 뜻합니다. __global__로 수식된 함수는 host에서 호출할 수는 있어도 device에서 호출할 수는 없습니다. 대신 device로 실행하는 커널 함수 지정에 사용할 수 있습니다. 다음은 __global__로 수식한 함수의 간단한 예입니다. 1234567891011121314151617181920212223#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio . h&gt;;__global__ void add(int a, int b, int *c) {  *c = a + b;}int main() {  int c;  int *dev_c;  cudaMalloc((void**)&amp;dev_c, sizeof(int));  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);  cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);  printf( 2 + 7 = %d\n , c);  cudaFree(dev_c);  return 0;}위와 같이 return type은 항상 void 형이어야 하며, 다른 return type은 가질 수 없습니다. 이것은 조금만 생각해보면 쉽게 그 이유를 알 수 있습니다. 지금의 예에서는 하나의 커널 함수만이 실행되었지만, 실제로는 수천, 수만 개의 커널 함수가 한꺼번에 실행될 것입니다. 만약 __global__ 함수의 리턴 타입이 void가 아니라면 수천, 수만 개의 커널 함수에서 제각각 return 값을 host로 넘겨주게 될 것입니다. 그러한 문제를 막기 위해 아예 void 형이 아닌 다른 return type을 가질 수 없도록 한 것입니다. 또, 함수의 호출 시에 &lt;&lt;&lt; block의 개수, thread의 개수 &gt;&gt;&gt;의 형식으로 block과 thread의 개수를 지정해 줄 수 있습니다. __global__ 함수는 device에서 실행되는 함수이지만 device에서는 호출할 수 없습니다. 즉, 재귀호출이 불가능합니다. 이것 또한 이 함수가 수만 개가 한꺼번에 실행되는 커널 함수라는 것을 생각해보면 그 이유를 쉽게 알 수 있습니다. 또한 함수 내에 static 변수를 가질 수 없으며, 가변형 인수를 가질 수 없는 등의 제약 사항이 존재합니다. 가변형 인수를 가질 수 없다는 것은 다음과 같은 식으로 함수를 호출하는 코드는 불가능하다는 것을 뜻합니다. 1  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(int a, int b, dev_c);또한 __global__ __host__와 같은 용법으로 쓰일 수 없고, 공유 메모리를 이용하며 256 바이트까지의 인수를 사용할 수 있습니다. __device__: 위의 __global__과 마찬가지로 device에서 실행되는 함수를 뜻합니다. 하지만 __global__과는 다르게 host에서 호출이 불가능하고, device에서만 호출이 가능합니다. 즉, __global__ 함수가 실행되었을 때 device 내에서 실행되는 서브 함수로 사용됩니다. device에서 실행되고 device에서 호출되기 때문에 재귀 호출이 가능하지 않느냐고 생각할 수도 있지만 마찬가지로 재귀호출은 할 수 없습니다. 1234567__device__ int subAdd(int a, int b) {  return a + b;}__global__ void add(int a, int b, int *c) {  *c = subAdd(a, b);}__global__에서 예시로 들었던 add 함수의 코드를 조금만 바꾼 __device__ 함수의 예시입니다. 실행시켜 보면 똑같은 결과값이 나오는 것을 알 수 있습니다. __global__ 함수는 device 내에서 실행되는 함수이기 때문에 __device__ 함수를 호출할 수 있습니다. 하지만 host에서는 호출할 수 없기 때문에 다음과 같은 호출은 불가능합니다. 12345678910111213141516#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;__device__ int subAdd(int a, int b) {  return a + b;}int main() {  int c;  c = subAdd(2, 7);  print( 2 + 7 = %d\n , c);  return 0;}위 코드를 실행시키면 다음과 같은 에러가 발생합니다. 1error : calling a __device__ function( subAdd ) from a __host__ function( main ) is not allowed즉, __host__ 함수인 main 함수에서 __device__ 함수인 subAdd 함수를 호출할 수 없다는 것입니다. 추가적으로, __device__ 함수 역시 __global__ 함수와 마찬가지로 static 변수를 함수 내에 가질 수 없고, 가변형 인수를 가질 수 없습니다. __host__: __host__ 함수는 위에서 언급했던 __global__이나 __device__ 함수와는 실행되는 위치부터가 다릅니다. host에서 실행되며, host에서만 호출할 수 있고, device에서는 호출할 수 없습니다. main 함수가 그 대표적인 예입니다. main 함수를 통해서 알 수 있드시, __global__, __device__, __host__ 등의 키워드가 지정되지 않은 경우에는 __host__를 지정한 것과 동일한 효과를 지닙니다. 123456789101112131415161718192021222324252627#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;;__device__ int subAdd(int a, int b) {  return a + b;}__global__ void add(int a, int b, int *c) {  *c = subAdd(a, b);}__host__ int main() {  int c;  int *dev_c;  cudaMalloc((void**)&amp;dev_c, sizeof(int));  add&lt;&lt;&lt;1, 1&gt;&gt;&gt;(2, 7, dev_c);  cudaMemcpy(&amp;c, dev_c, sizeof(int), cudaMemcpyDeviceToHost);  printf( 2 + 7 = %d\n , c);  cudaFree(dev_c);  return 0;}위의 코드처럼 main 함수를 __host__로 지정해주어도 아무런 문제 없이 잘 실행이 됩니다. 이는 main 함수가 __host__ 함수이기 때문이며, 어떤 함수인지 지정해주지 않았을 때는 default로 __host__로 지정되기 때문입니다. __host__ 수식어는 __global__ 수식어와 동시에 사용할 수는 없지만, __device__ 수식어와는 함께 사용할 수 있습니다. 바로 __device__ __host__와 같은 방법으로 사용하는 것인데요. 이에 대해서는 아래에서 따로 설명하도록 하겠습니다. __device__ __host__: __host__ 수식어와 __device__ 수식어를 동시에 사용한 경우입니다. 이 경우 host와 device 양쪽에서 모두 사용할 수 있는 함수로 작성할 수 있습니다. 1234567891011121314151617#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;;__device__ __host__ int subAdd(int a, int b) {  return a + b;}int main() {  int c;  c = subAdd(2, 7);  printf( 2 + 7 = %d\n , c);  return 0;}위 코드를 실행시키면 역시나 아무런 문제 없이 잘 동작합니다. 이는 subAdd 함수가 host와 device 모두에서 사용할 수 있는 함수이기 때문입니다. 이러한 수식어를 사용하는 것이 무척이나 편리한 경우가 가끔 생기는데, host와 device 모두에서 호출하는 간단한 계산 같은 것을 __device__ __host__ 함수로 지정하여 사용하는 경우가 있습니다. 같은 내용의 함수를 device 용, host 용으로 두 개나 만들지 않고, 하나의 함수로 해결하는 것입니다. 그 때문에 device와 host 모두에서 사용가능한 함수가 필요했고, 이 함수는 host와 device 각각 호출이 가능하며, 호출된 곳(host라면 host, device라면 device)에서 실행될 필요가 있었습니다. 따라서 __global__ 키워드는 제외되고, __device__ __host__와 같은 형식으로 device와 host 모두에서 사용 가능하도록 만들어진 것입니다. 포스팅의 내용이 길어서 CUDA C 확장 키워드에 대해서 다음 포스팅에서 이어서 설명하도록 하겠습니다. 다음 포스팅에서는 변수의 수식어에 대해 이야기하도록 하겠습니다. "
    }, {
    "id": 5,
    "url": "http://localhost:4000/cuda-syntax-device/",
    "title": "[CUDA 5.0] CUDA syntax를 이용하여 device 정보 불러오기",
    "body": "2015/04/02 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. 본격적인 CUDA 코딩에 앞서 CUDA syntax를 이용하여 device의 정보를 불러오는 방법에 대해 소개하려고 합니다. 여기서 말하는 device란 CUDA acceleration(CUDA 가속)을 지원하는 GPU를 뜻합니다. 아래의 코드는 CUDA syntax를 이용하여 device의 정보를 불러와 출력하는 내용입니다. 123456789101112131415161718192021222324252627#include  cuda_runtime. h #include  device_launch_parameters. h #include &lt;stdio. h&gt;int main() {  int i;  cudaDeviceProp prop;  int count;  cudaGetDeviceCount(&amp;count);  for (i = 0 ; i &lt; count ; i++) {    cudaGetDeviceProperties(&amp;prop, i);    printf( -- %d번째 디바이스 --\n , i+1);    printf(  (1) 장치 이름 : %s\n , prop. name);    printf(  (2) Clock Rate : %d\n , prop. clockRate);    printf(  (3) 전역 메모리 용량 : %ld\n , prop. totalGlobalMem);    printf(  (4) 상수 메모리 용량 : %ld\n , prop. totalConstMem);    printf(  (5) Register per block : %d\n , prop. regsPerBlock);    printf(  (6) Max Grid Size : %d\n , prop. maxGridSize);    printf(  (7) Max Thread Dimension : %d\n , prop. maxThreadsDim);    printf(  (8) Max Thread per block : %d\n , prop. maxThreadsPerBlock);  }  return 0;}CUDA는 cudaDeviceProp이라는 구조체 형식에 device들의 정보를 저장하게 됩니다. 이를 이용하면 device의 다양한 정보를 불러올 수 있습니다. 아래는 위 코드를 실행시킨 결과입니다.  출력된 결과를 살펴보면, GeForce GT 750M이라는 하나의 device를 사용 중이며, clock rate나 메모리 용량이 얼마인지 알 수 있습니다. cudaDeviceProp은 이외에도 다양한 정보를 제공합니다. 이러한 데이터를 잘 활용하면 효과적인 CUDA 코딩을 할 수 있을 것입니다. 그러면 위 코드를 자세히 살펴봅시다. 1  cudaDeviceProp prop;Device property의 출력을 위해 구조체를 생성한 것입니다. 위에서 잠깐 언급했듯이 CUDA는 device의 정보를 구조체 형식에 저장합니다. cudaDeviceProp 구조체는 driver_types. h 파일에 선언되어 있으며, 이러한 header file들은 CUDA project를 생성하면 외부 종속성 폴더에 추가되도록 되어 있습니다. 아래는 cudaDeviceProp 구조체의 선언 부분입니다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * CUDA device properties */struct __device_builtin__ cudaDeviceProp{  char  name[256];         /**&lt; ASCII string identifying device */  size_t totalGlobalMem;       /**&lt; Global memory available on device in bytes */  size_t sharedMemPerBlock;     /**&lt; Shared memory available per block in bytes */  int  regsPerBlock;        /**&lt; 32-bit registers available per block */  int  warpSize;          /**&lt; Warp size in threads */  size_t memPitch;          /**&lt; Maximum pitch in bytes allowed by memory copies */  int  maxThreadsPerBlock;     /**&lt; Maximum number of threads per block */  int  maxThreadsDim[3];      /**&lt; Maximum size of each dimension of a block */  int  maxGridSize[3];       /**&lt; Maximum size of each dimension of a grid */  int  clockRate;         /**&lt; Clock frequency in kilohertz */  size_t totalConstMem;       /**&lt; Constant memory available on device in bytes */  int  major;           /**&lt; Major compute capability */  int  minor;           /**&lt; Minor compute capability */  size_t textureAlignment;      /**&lt; Alignment requirement for textures */  size_t texturePitchAlignment;   /**&lt; Pitch alignment requirement for texture references bound to pitched memory */  int  deviceOverlap;       /**&lt; Device can concurrently copy memory and execute a kernel. Deprecated. Use instead asyncEngineCount. */  int  multiProcessorCount;    /**&lt; Number of multiprocessors on device */  int  kernelExecTimeoutEnabled;  /**&lt; Specified whether there is a run time limit on kernels */  int  integrated;         /**&lt; Device is integrated as opposed to discrete */  int  canMapHostMemory;      /**&lt; Device can map host memory with cudaHostAlloc/cudaHostGetDevicePointer */  int  computeMode;        /**&lt; Compute mode (See ::cudaComputeMode) */  int  maxTexture1D;        /**&lt; Maximum 1D texture size */  int  maxTexture1DMipmap;     /**&lt; Maximum 1D mipmapped texture size */  int  maxTexture1DLinear;     /**&lt; Maximum size for 1D textures bound to linear memory */  int  maxTexture2D[2];      /**&lt; Maximum 2D texture dimensions */  int  maxTexture2DMipmap[2];   /**&lt; Maximum 2D mipmapped texture dimensions */  int  maxTexture2DLinear[3];   /**&lt; Maximum dimensions (width, height, pitch) for 2D textures bound to pitched memory */  int  maxTexture2DGather[2];   /**&lt; Maximum 2D texture dimensions if texture gather operations have to be performed */  int  maxTexture3D[3];      /**&lt; Maximum 3D texture dimensions */  int  maxTextureCubemap;     /**&lt; Maximum Cubemap texture dimensions */  int  maxTexture1DLayered[2];   /**&lt; Maximum 1D layered texture dimensions */  int  maxTexture2DLayered[3];   /**&lt; Maximum 2D layered texture dimensions */  int  maxTextureCubemapLayered[2];/**&lt; Maximum Cubemap layered texture dimensions */  int  maxSurface1D;        /**&lt; Maximum 1D surface size */  int  maxSurface2D[2];      /**&lt; Maximum 2D surface dimensions */  int  maxSurface3D[3];      /**&lt; Maximum 3D surface dimensions */  int  maxSurface1DLayered[2];   /**&lt; Maximum 1D layered surface dimensions */  int  maxSurface2DLayered[3];   /**&lt; Maximum 2D layered surface dimensions */  int  maxSurfaceCubemap;     /**&lt; Maximum Cubemap surface dimensions */  int  maxSurfaceCubemapLayered[2];/**&lt; Maximum Cubemap layered surface dimensions */  size_t surfaceAlignment;      /**&lt; Alignment requirements for surfaces */  int  concurrentKernels;     /**&lt; Device can possibly execute multiple kernels concurrently */  int  ECCEnabled;         /**&lt; Device has ECC support enabled */  int  pciBusID;          /**&lt; PCI bus ID of the device */  int  pciDeviceID;        /**&lt; PCI device ID of the device */  int  pciDomainID;        /**&lt; PCI domain ID of the device */  int  tccDriver;         /**&lt; 1 if device is a Tesla device using TCC driver, 0 otherwise */  int  asyncEngineCount;      /**&lt; Number of asynchronous engines */  int  unifiedAddressing;     /**&lt; Device shares a unified address space with the host */  int  memoryClockRate;      /**&lt; Peak memory clock frequency in kilohertz */  int  memoryBusWidth;       /**&lt; Global memory bus width in bits */  int  l2CacheSize;        /**&lt; Size of L2 cache in bytes */  int  maxThreadsPerMultiProcessor;/**&lt; Maximum resident threads per multiprocessor */};위와 같이 선언되어 있는데, 각각 어떤 것을 의미하는지는 각 항목마다 설명이 주석처리 되어 있으므로 자세한 설명은 하지 않겠습니다. 앞서 출력해 보았던 내용 이외에도 엄청나게 많은 정보들을 저장하고 있지만, 가장 많이 쓰이게 될 몇 가지 정보들만 출력해 보았습니다. 12  int count;  cudaGetDeviceCount(&amp;count);device 장치의 개수를 획득하는 함수입니다. int 형 변수인 count를 만들고, 그것의 주소값을 argument로 넘겨주게 됩니다. cudaGetDeviceCount 함수는 cuda_runtime_api. h에 다음과 같이 정의되어 있습니다. 1extern __host__ __cudart_builtin__ cudaError_t CUDARTAPI cudaGetDeviceCount(int *count);parameter로 count의 포인터를 넘겨 받기 때문에 호출 시 argument의 사용에 주의해 주셔야 합니다. 함수의 이름에서 알 수 있다시피 count 변수에는 device의 개수 값이 들어갑니다. CUDA 뿐만이 아니라 다른 언어나 tool을 공부할 때에도 마찬가지로, 어떤 함수를 사용할 때 그것이 어떻게 정의되어 있는지 내부를 공부하는 것은 무척이나 많은 도움이 됩니다. 특히나 CUDA는 C 기반으로 짜여져 있는데다 주석도 잘 달려 있어 공부하기 편리합니다. 이렇게 CUDA syntax를 이용하여 device의 정보를 출력하는 방법에 대해 알아보았습니다. 이후 포스팅에서 CUDA 병렬 프로그래밍에 대해 더 자세히 알아보도록 하겠습니다. "
    }, {
    "id": 6,
    "url": "http://localhost:4000/cuda-syntax-highlighting/",
    "title": "[CUDA 5.0] CUDA Syntax Highlighting 설정하기",
    "body": "2015/04/01 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. VS에서 CUDA 코드를 작성하면 CUDA Syntax Highlighting은 물론이고 기본적인 C/C++ 문법마저도 Syntax Highlighting이 되지 않아 코드를 작성하기 무척이나 번거롭고 힘들었을 것입니다. 따라서, 이번 포스팅에서는 CUDA Syntax Highlighting 방법에 대해 소개하려 합니다. 이전 버전들과는 방법이 다르기 때문에, 다른 버전을 사용 중이라면 적용되지 않을 수도 있다는 점을 염두에 두시길 바랍니다. 우선 VS를 켜고, 상단 메뉴 바에서 도구 -&gt; 옵션으로 들어갑니다. 창이 하나 나타나는데, 여기서 프로젝트 및 솔루션 -&gt; VC++ 프로젝트 설정으로 들어가면 아래의 창 같은 화면이 뜹니다. 이 중 포함할 확장명에 . cu; cuh;를 추가합니다. 확장자명끼리의 구분은 ;로 구분하게 됩니다. . cu 파일은 CUDA source file이고, . cuh 파일은 CUDA header file입니다.  확장명에 추가했으면 이제 . cu와 . cuh를 C++ 편집 환경으로 설정해 줄 차례입니다. 옵션 창에서 텍스트 편집기 -&gt; 파일 확장명으로 들어가면, 아래와 같은 창이 나타납니다. 여기에 확장명 . cu, 편집기 Microsoft Visual C++을 선택하고 적용하면 됩니다. . cuh도 마찬가지 방법으로 적용해 줍니다.  이제 C:\ProgramData\NVIDIA Corporation\CUDA Samples\v5. 0\doc\syntax_highlighting\visual_studio_8 폴더로 들어가보면 usertype. dat 파일이 있을 것입니다. 이 파일을 C:\Program Files\Microsoft Visual Studio 10. 0\Common7\IDE 폴더에 복사해 넣으면 됩니다. 주소는 32bit 기준이므로, 64bit라면 Program Files (x86) 폴더에서 찾아 복사해 넣도록 합니다.  이것으로 CUDA Syntax Highlighting 준비가 모두 끝났습니다. VS를 다시 시작하거나 아니면 프로젝트를 다시 열면 문법에 맞는 색깔로 설정된 C/C++ 코드를 볼 수 있을 것입니다. 참고로, CUDA Syntax Highlighting을 위해서는 아래의 두 줄을 추가로 입력해 주어야지만 정상적으로 표현이 됩니다. 12#include  cuda_runtime. h #include  device_launch_parameters. h 이 두 줄은 모두 CUDA Project를 생성하면 만들어지는 kernel. cu에 포함되어 있습니다.  위는 정상적으로 CUDA Syntax Highlighting이 적용된 코드입니다. __global__이나 threadIdx와 같은 CUDA 문법들에도 highlighting이 적용된 것을 확인할 수 있습니다. 참고로 위 화면에서는 다른 테마가 적용되어 있으므로, 실제로 highlighting을 적용했을 때 다르게 보일 수 있습니다. "
    }, {
    "id": 7,
    "url": "http://localhost:4000/cuda-%EC%98%88%EC%A0%9C-%EC%8B%A4%ED%96%89%ED%95%98%EA%B8%B0/",
    "title": "[CUDA 5.0] CUDA 예제 실행하기",
    "body": "2015/03/31 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. CUDA 5. 0을 설치하고, 리부팅을 하고 나면 NVIDIA CUDA Samples Browser v5. 0 아이콘이 생겼을 것입니다. 이름만으로도 어떤 프로그램인지 감이 오시나요? CUDA 5. 0부터는 Installer에 samples 또한 포함이 되어 있다고 저번 포스팅에서 언급하였습니다. 이 프로그램이 바로 설치와 같이 다운 받은 예제 파일들을 찾아보고, 실행해 볼 수 있는 프로그램입니다. 한 번 실행해 봅시다.  실행하면 보이는 바와 같이 다양한 샘플들을 찾아볼 수 있고, 실행시켜 볼 수도 있습니다. 이 샘플들을 실행시켰을 때, 아무 무리 없이 잘 돌아가면 설치가 제대로 되었다는 뜻입니다. 만약 실행이 되지 않는다면, 컴퓨터에 설치되어 있는 GPU가 CUDA 가속을 지원하는지를 확인하고, 또 NVIDIA 그래픽 드라이버가 최신 버전인지를 확인해 주세요. 이 중 CUDA N-Body Simulation을 실행시켜 봅시다. N-Body가 무엇인지 몰라도 어떤 프로그램인지는 그래픽으로 시뮬레이션해주기 때문에 알아보기 쉽습니다. 실행하는 방법은 오른쪽 편에 작은 글씨로 된 Run을 누르면 됩니다. 실행하면 다음과 같은 창 하나가 뜹니다. 이 창에서는 프로그램에 대한 간단한 설명 등과 함께 맨 아래쪽에 보면 어떤 device를 사용하고 있는지에 대한 정보도 같이 볼 수 있습니다. simulation을 위해 하나의 device를 사용하였고, 그 device는 GeForce 310M이라는 정보가 뜹니다. 이 정보는 각자 사용하는 GPU에 따라 다르게 나타날 것입니다.  그리고 하나 더 뜨는 창에서는 다음과 같이 N-Body Simulation이 이루어집니다. 현재 시뮬레이션 되고 있는 상태에 대해서는 화면 위쪽에 나타나게 되고, 화면 전체에 N-Body Simulation이 약간의 끊김이 있기는 하지만 빠르고 매끄럽게 진행되는 것을 확인할 수 있습니다. 심지어 310M이라는 낮은 사양의 GPU에서도 말이죠.  NVIDA CUDA Samples Browser에서는 이러한 N-Body Simulation 이외에도 다양한 예제들을 실행시켜 볼 수 있습니다. 그리고 이러한 예제들의 코드 역시 같이 다운받아져 있는데, 이 코드들은 C:\ProgramData\NVIDIA Corporation\CUDA Samples\v5. 0 폴더에 잘 정리되어 있습니다. ProgramData 폴더는 숨겨져 있는 폴더이므로 C 드라이브에 들어갔는데 폴더가 없다고 당황하지 않으셔도 됩니다. 위 주소로 들어가보면 다음과 같이 잘 정리된 CUDA 예제들의 코드를 확인하고, 직접 실행시켜 볼 수 있습니다.  아까 위에서 실행시켜 보았던 N-Body Simulation은 5_Simulation 폴더에 nbody라는 이름으로 들어가 있습니다. VS에서 실행시켜 보면 앞서 실행시켰던 것과 같은 결과가 나오는 것을 확인할 수 있습니다. 예제 파일들은 간단한 것부터 복잡하고 어려운 계산이나 그래픽을 요하는 것까지 다양하게 제공되므로, 예제 파일을 분석하며 공부하는 것도 많은 도움이 될 것입니다. CUDA를 공부하면 C/C++로 이미 만들어져 있는 프로그램을 포팅하는 것을 주로 하게 되고, 어떻게 최적화를 하느냐에 따라 같은 내용을 실행시키더라도 성능이 확연하게 달라질 수 있습니다. 따라서 이미 잘 짜여져 있는 성능 좋은 코드를 많이 보는 것이 공부에 도움이 될 것입니다. CUDA Project는 C/C++ Project를 그대로 이용해도 상관 없으나, VS에서는 CUDA를 설치하면 다음과 같이 CUDA 5. 0 Runtime Project를 바로 생성할 수 있도록 해 줍니다.  CUDA 5. 0 Rumtime Project를 생성하면 따로 무언가를 설정할 필요 없이 바로 컴파일이나 빌드를 할 수 있도록 되어 있습니다. 생성하면 kernel. cu라는 소스 파일 하나가 공통적으로 들어가 있는데요. 여기에는 1차원 array를 더하는 내용의 코드가 포함되어 있습니다. 무척 간단한 코드로 실행시켜 보면 다음과 같은 결과가 출력됩니다.  이것으로 CUDA 예제를 가능한 모든 방법을 동원하여 실행하여 보았습니다. CUDA는 아직 한글로 번역된 책이 많이 없기 때문에 이미 만들어져 있는 예제들을 보면서 실행시켜 보고, 스스로 분석하고, 다른 코드를 CUDA로 포팅해보는 연습을 하다 보면 실력이 많이 느는 것을 확인할 수 있을 것입니다. 자, 이렇게 CUDA 5. 0을 사용하여 코딩할 준비가 모두 끝났습니다. 다음 포스팅에서는 위 화면에 보이는 바와 같이 CUDA Syntax Highlighting 하는 방법에 대해서 이야기하도록 하겠습니다. "
    }, {
    "id": 8,
    "url": "http://localhost:4000/cuda-%EC%84%A4%EC%B9%98%ED%95%98%EA%B8%B0/",
    "title": "[CUDA 5.0] CUDA 설치하기",
    "body": "2015/03/30 - ※ 이 글은 2013년도에 작성된 글입니다. 사진이나 세부적인 내용은 지금과 다를 수 있습니다. CUDA 5. 0은 이전 버전들과는 달리 설치가 매우 간편해진 것이 특징입니다. NVIDIA 사이트에서 CUDA ZONE을 들어가면 영어로 된 developer zone이 나오는데, 여기서 CUDA Download를 클릭해 들어가면 다음과 같은 페이지가 뜹니다. 참고로, NVIDIA Korea 사이트에서는 한글 번역을 지원해주지만 developer zone은 한글 번역을 지원해주지 않습니다. 또, 한국 사이트에서는 낮은 버전의 CUDA를 다운받게 되므로 꼭 원래 사이트에 들어가서 다운 받아 주세요.  여기서 Desktop/Notebook의 OS 등에 맞는 파일을 클릭하여 다운 받을 수 있습니다. CUDA 5. 0부터는 CUDA Toolkit과 SDK code samples, developer driver를 모두 한꺼번에 다운 받아 설치할 수 있어 무척이나 간편하게 설치할 수 있게 되어 있습니다. 다운 받은 installer를 실행하면 설치가 끝납니다. 설치가 끝나면 컴퓨터를 리부팅해야 CUDA를 사용할 수 있습니다. 자신의 GPU가 CUDA 가속을 지원하는 지에 대해서는 CUDA ZONE에서 CUDA GPUs를 들어가면 확인할 수 있습니다. Tesla, Quadro, NVS, GeForce 순으로 나와 있습니다. 현재는 대부분의 GPU들이 CUDA 가속을 지원합니다.  한 가지 더. CUDA를 사용하기 위해서는 그래픽 드라이버가 최신 버전이어야 합니다. NVIDIA 사이트에서 다운 받을 수 있으니 최신 버전인지를 확인하고 업데이트 하도록 합시다. 혹시 이후에 실행을 시켰는데 되지 않는다면 그래픽 드라이버가 최신 버전이 아니기 때문일 수도 있습니다. 자, 이렇게 CUDA 5. 0을 설치하여 사용할 준비가 끝났습니다. CUDA 5. 0에서는 다양한 예제 파일들을 같이 다운 받았기 때문에 그것들을 실행시켜 볼 수 있습니다. 예제 파일의 실행에 대해서는 다음 포스팅 때 이야기하도록 하겠습니다. "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});